<!-- build time:Tue Jul 12 2022 23:33:36 GMT+0800 (China Standard Time) --><!DOCTYPE html><html lang="zh-HK"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="2022" href="https://fygod1999.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="2022" href="https://fygod1999.github.io/atom.xml"><link rel="alternate" type="application/json" title="2022" href="https://fygod1999.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Inconsolata:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><meta name="keywords" content="思考,Python,考前复习,卷积神经网络,深度学习"><link rel="canonical" href="https://fygod1999.github.io/2022/04/20/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><title>卷积神经网络 - 盲人摸象 | Scarecrow = 2022</title><meta name="generator" content="Hexo 6.2.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">卷积神经网络</h1><div class="meta"><span class="item" title="創建時間：2022-04-20 20:58:40"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">發表於</span> <time itemprop="dateCreated datePublished" datetime="2022-04-20T20:58:40+08:00">2022-04-20</time> </span><span class="item" title="本文字數"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">本文字數</span> <span>6.9k</span> <span class="text">字</span> </span><span class="item" title="閱讀時長"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">閱讀時長</span> <span>6 分鍾</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切換導航欄"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Scarecrow</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://cdn.fygod.xyz/uploads/2022/05/27/Y4m35hX4_wallhaven-o38yol.jpg"></li><li class="item" data-background-image="https://cdn.fygod.xyz/uploads/2022/06/26/NSUwXjVY_97447F90-3283-46D4-B00E-88D8447A0075.jpeg"></li><li class="item" data-background-image="https://cdn.fygod.xyz/uploads/2022/06/28/wcg6VGjO_wallhaven-l315vy.png"></li><li class="item" data-background-image="https://cdn.fygod.xyz/uploads/2022/06/15/s0lqNEwt_wallhaven-9mve8x.png"></li><li class="item" data-background-image="https://cdn.fygod.xyz/uploads/2022/06/26/cH8P1KSH_wallhaven-y868r7.jpg"></li><li class="item" data-background-image="https://cdn.fygod.xyz/uploads/2022/06/14/CfNAEOmT_wallhaven-2kl9o6.jpg"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首頁</a></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/%E7%9B%B2%E4%BA%BA%E6%91%B8%E8%B1%A1/" itemprop="item" rel="index" title="分類於 盲人摸象"><span itemprop="name">盲人摸象</span></a><meta itemprop="position" content="1"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-HK"><link itemprop="mainEntityOfPage" href="https://fygod1999.github.io/2022/04/20/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="fygod"><meta itemprop="description" content=", 孤舟蓑笠翁，獨釣寒江雪"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="2022"></span><div class="body md" itemprop="articleBody"><h2 id="局部连接-权值共享-多核卷积"><a class="anchor" href="#局部连接-权值共享-多核卷积">#</a> 局部连接、权值共享、多核卷积</h2><h3 id="局部连接"><a class="anchor" href="#局部连接">#</a> 局部连接</h3><p>传统的神经网络是一种层级的结构，由输入层、隐藏层、输出层构成，每一层神经元与下一层神经元完全连接，神经元之间不存在同层之间的连接，也不存在跨层连接。相比传统神经网络，卷积神经网络引入<span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vc2hpbmUtbGVlL3AvMTIwNjkxNzYuaHRtbA==">感受野</span> <code>receptive field</code> 的概念（局部连接），即每一个神经元只与上一层的部分神经元相连接，只感受局部的图像，而非整体的图像。</p><p><img data-src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/089f65574a3f43eb91ed0dada05b8f3d~tplv-k3u1fbpfcp-watermark.image?" alt="205938ufntootfhw4wwort.gif"></p><h3 id="权值共享"><a class="anchor" href="#权值共享">#</a> 权值共享</h3><p>其次，每一个神经元都可视为一个滤波器，同一个神经元使用一个固定的卷积核，固定的卷积核卷积上一层的整张图像。假设卷积核为 <code>m*m</code> ，进行权值共享时总参数个数为 <code>m*m*channels</code> ；若不进行此步，总参数量变为原来的若干倍 <code>W*H*channels</code> 。如果在局部连接中，每个神经元都对应 <code>100</code> 个参数，一共 <code>10^6</code> 个神经元，如果这 <code>10^6</code> 个神经元的 <code>100</code> 个参数都是相等的，那么参数数目就变为 <code>100</code> 了。</p><p><img data-src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7c59c606e91c433caf1c63b4c874956c~tplv-k3u1fbpfcp-watermark.image?" alt="205706hslee3hxplxd2gex.gif"></p><p>以上两步<strong>降低了参数量，加速训练速度。</strong></p><p>图片来自<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLnNjaWVuY2VuZXQuY24vYmxvZy0zNDI4NDY0LTEyNTUyNTIuaHRtbA=="># 轻松理解局部连接和权值共享</span></p><h3 id="多核卷积"><a class="anchor" href="#多核卷积">#</a> 多核卷积</h3><p>在处理图像时，为了提供特征多样性，构建了多卷积核，提出了通道维度；通过使用多个卷积核来提取多个特征，选择多个卷积核，生成不同的图像。这些不同图像可以理解为不同通道。</p><p><img data-src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d7702260554f44668bbe4120d1fa3c62~tplv-k3u1fbpfcp-watermark.image?" alt="0.gif"></p><h2 id="卷积神经网络的基本单元"><a class="anchor" href="#卷积神经网络的基本单元">#</a> 卷积神经网络的基本单元</h2><ul><li>卷积层</li><li>激活函数层</li><li>池化层</li><li>归一化层（可能有）</li><li>全连接层</li></ul><p><img data-src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9ccf4a630424417fb71e2a41802a565c~tplv-k3u1fbpfcp-watermark.image?" alt="image.png"></p><h3 id="卷积层"><a class="anchor" href="#卷积层">#</a> 卷积层</h3><p>感受野阐述了卷积层中每个神经元与输入数据体之间的连接方式，但是尚未讨论输入数据体中神经元的数量，以及它们的排列方式。以下几个超参数控制着输出数据体的尺寸：</p><ul><li>卷积核的尺寸<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>F</mi><mi>W</mi></msub></mrow><annotation encoding="application/x-tex">F_W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.32833099999999993em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>F</mi><mi>H</mi></msub></mrow><annotation encoding="application/x-tex">F_H</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.32833099999999993em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.08125em">H</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span></li><li>输出数据体的深度：和使用的滤波器的数量一致，而每个滤波器在输入数据中寻找一些不同的东西，即图像的某些特征。</li><li>滑动滤波器的步长：当步长为 <code>1</code> ，滤波器每次移动 <code>1</code> 个像素；当步长为 <code>2</code> ，滤波器滑动时每次移动 <code>2</code> 个像素，当然步长也可以是不常用的 <code>3</code> ，或者更大的数字，但这些在实际中很少使用）。这个操作会让输出数据体在空间上变小。</li><li>零填充尺寸：原图边界点被使用的次数较少，经过卷积，特征无法清晰展示，所以需要将外围扩充；为什么用 <code>0</code> 来填充；因为 <code>0</code> 乘任何数还是 <code>0</code> ，卷积之后对原来的结果没有影响。零填充 <code>P</code> 为原图外围包着几层 <code>0</code> 。<br>Accepts a volume of size <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mn>1</mn><mo>∗</mo><mi>H</mi><mn>1</mn><mo>∗</mo><mi>D</mi><mn>1</mn></mrow><annotation encoding="application/x-tex">W1*H1*D1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.08125em">H</span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.02778em">D</span><span class="mord">1</span></span></span></span></li></ul><p>如果不进行零填充，输出尺寸为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mo>=</mo><mfrac><mrow><mi>W</mi><mo>−</mo><msub><mi>F</mi><mi>W</mi></msub></mrow><mi>S</mi></mfrac><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">W=\frac{W-F_W}{S}+1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.2336359999999997em;vertical-align:-.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8886359999999999em"><span style="top:-2.6550000000000002em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.05764em">S</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.410305em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">W</span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3448em"><span style="top:-2.3567071428571427em;margin-left:-.13889em;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.14329285714285717em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">1</span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mo>=</mo><mfrac><mrow><mi>H</mi><mo>−</mo><msub><mi>F</mi><mi>H</mi></msub></mrow><mi>S</mi></mfrac><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">H=\frac{H-F_H}{S}+1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.08125em">H</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.2336359999999997em;vertical-align:-.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8886359999999999em"><span style="top:-2.6550000000000002em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.05764em">S</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.410305em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.08125em">H</span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3448em"><span style="top:-2.3567071428571427em;margin-left:-.13889em;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:.08125em">H</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.14329285714285717em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">1</span></span></span></span></p><p><img data-src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ff138f5b029b45dd9556601e346fd019~tplv-k3u1fbpfcp-watermark.image?" alt="image.png"></p><p>加入零填充</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>W</mi><mn>2</mn></msub><mo>=</mo><mfrac><mrow><msub><mi>W</mi><mn>1</mn></msub><mo>−</mo><msub><mi>F</mi><mi>W</mi></msub><mo>+</mo><mn>2</mn><mi>P</mi></mrow><mi>S</mi></mfrac><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">W_2=\frac{W_1-F_W+2P}{S}+1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.04633em;vertical-align:-.686em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.05764em">S</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.32833099999999993em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:.13889em">P</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">1</span></span></span></span></span></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>H</mi><mn>2</mn></msub><mo>=</mo><mfrac><mrow><msub><mi>H</mi><mn>1</mn></msub><mo>−</mo><msub><mi>F</mi><mi>H</mi></msub><mo>+</mo><mn>2</mn><mi>P</mi></mrow><mi>S</mi></mfrac><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">H_2=\frac{H_1-F_H+2P}{S}+1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.08125em">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.08125em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.04633em;vertical-align:-.686em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.05764em">S</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:.08125em">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.08125em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.32833099999999993em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.08125em">H</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:.13889em">P</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">1</span></span></span></span></span></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>D</mi><mn>2</mn></msub><mo>=</mo><msub><mi>D</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">D_2=D_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span></span></p><p>一般说来，当步长<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">S = 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.05764em">S</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">1</span></span></span></span> 时，零填充的值是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo>=</mo><mfrac><mrow><mi>F</mi><mo>−</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><annotation encoding="application/x-tex">P=\frac{F-1}{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.217331em;vertical-align:-.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.872331em"><span style="top:-2.6550000000000002em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">F</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>，这样能保证输入和输出数据体有相同的空间尺寸。</p><p><strong>Example</strong></p><p><img data-src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/864aab9e7c9043a391510a7e774205c7~tplv-k3u1fbpfcp-watermark.image?" alt="image.png"></p><p>the answer is <code>32*32*10</code></p><p>And the number of parameters in this layer?</p><p>each filter has <code>5*5*3 + 1 = 76 params (+1 for bias)</code></p><p>so the answer is <code>76 * 10 = 760</code></p><h3 id="激活函数层"><a class="anchor" href="#激活函数层">#</a> 激活函数层</h3><p>激活函数本身就是 <code>neuron model</code> 的一部分，不是从属于 <code>CNN</code> 或者是 <code>RNN</code> 。</p><p>如果输入变化很小，导致输出结构发生截然不同的结果，这种情况是我们不希望看到的，为了模拟更细微的变化，输入和输出数值不只是 <code>0</code> 到 <code>1</code> ，可以是 <code>0</code> 和 <code>1</code> 之间的任何数。</p><p>对于图像，我们主要采用了卷积的方式来处理，也就是对每个像素点赋予一个权值，这个操作显然就是线性的。但是对于我们样本来说，不一定是线性可分的，为了解决这个问题，我们可以进行线性变化，或者我们引入非线性因素，解决线性模型所不能解决的问题由于线性模型的表达力不够，所以引入激活函数加入非线性因素，将一个特征空间的向量通过非线性变换映射到另一个空间，实现线性可分。</p><p>常用的激活函数： <code>Sigmoid</code> 、 <code>ReLU</code> 、 <code>Leaky ReLU</code> 、 <code>Maxout</code></p><p><strong>Sigmoid</strong></p><p><img data-src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/cc2af55a65d74c54b51bd8ba7b275e9d~tplv-k3u1fbpfcp-watermark.image?" alt="image.png"></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>σ</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>x</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\sigma(x)=\frac{1}{1+e^{-x}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.09077em;vertical-align:-.7693300000000001em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.697331em"><span style="top:-2.989em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathnormal mtight">x</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.7693300000000001em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mi>σ</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo lspace="0em" rspace="0em">×</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>σ</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\sigma&#x27;(x)=\sigma(x){\times}(1-\sigma(x))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.051892em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.801892em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mord"><span class="mord">×</span></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></span></p><p>依据链式法则求导时，梯度从后向前传播，每传递一层梯度值都会减小为原来的 <code>0.25</code> 倍，如果网络足够深，那么梯度在穿过多层后会变得非常小，接近于 <code>0</code> ，即梯度消失现象。</p><p>此外，经 <code>Sigmoid</code> 激活函数线性输出后的值并不满足均值为 <code>0</code> ，会使后层得到非 <code>0</code> 信号作为神经元的输入，使得参数在反向传播的时候会偏向更新（即都往正方向或都往负方向），收敛缓慢。</p><p><strong>ReLU</strong></p><p>针对 <code>Sigmoid</code> 梯度饱和导致训练收敛缓慢的问题， <code>AlexNet</code> 中首次引入了 <code>ReLU</code> 激活函数。</p><p><img data-src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5c1ab103dccd4d098100b44de7f22124~tplv-k3u1fbpfcp-watermark.image?" alt="image.png"></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>σ</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\sigma(x)=max(0,x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">a</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></span></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mi>σ</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.3599999999999999em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>x</mi><mo>&lt;</mo><mn>0</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>x</mi><mo>&gt;</mo><mn>0</mn></mrow></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">\sigma&#x27;(x)=\begin{cases} 0 &amp; x &lt; 0 \\ 1 &amp; x&gt;0 \end{cases}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.051892em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.801892em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:3.0000299999999998em;vertical-align:-1.25003em"></span><span class="minner"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size4">{</span></span><span class="mord"><span class="mtable"><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.69em"><span style="top:-3.69em"><span class="pstrut" style="height:3.008em"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-2.25em"><span class="pstrut" style="height:3.008em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.19em"><span></span></span></span></span></span><span class="arraycolsep" style="width:1em"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.69em"><span style="top:-3.69em"><span class="pstrut" style="height:3.008em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord">0</span></span></span><span style="top:-2.25em"><span class="pstrut" style="height:3.008em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.19em"><span></span></span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><ul><li>计算开销小， <code>Sigmoid</code> 的正向传播有指数运算和倒数运算，而 <code>ReLU</code> 是线性输出，反向传播中， <code>Sigmoid</code> 有指数运算，而 <code>ReLU</code> 有输出的部分，导数始终为 <code>1</code> ；</li><li>稀疏性， <code>ReLU</code> 会使一部分神经元的输出为 <code>0</code> ，即网络会变得稀疏，并且减少了参数的相互依存关系，缓解了过拟合问题的发生。</li></ul><p><code>ReLU</code> 并非没有缺点， <code>ReLU</code> 以非零为中心且在零点处不可微；此外，由于 <code>ReLU</code> 在 <code>x&lt;0</code> 时梯度为 <code>0</code> ，这样就导致负的梯度在这个 <code>ReLU</code> 被置零，而且这个神经元有可能再也不会被任何数据激活，正所谓神经元<em>坏死</em>影响神经网络的性能，决定了其使用场合只能用于隐藏层。</p><p><strong>Leaky ReLU</strong></p><p>针对 <code>ReLU</code> 中负梯度导致神经元<em>坏死</em>的情况，将输入小于 <code>0</code> 的部分赋予微小的梯度 <code>a</code> 。</p><p><img data-src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/046fd59a7fc74c6a84999ea58e6690c2~tplv-k3u1fbpfcp-watermark.image?" alt="image.png"></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>σ</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mi>a</mi><mi>x</mi><mo separator="true">,</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\sigma(x)=max(ax,x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">a</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></span></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mi>σ</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.3599999999999999em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mi>a</mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>x</mi><mo>&lt;</mo><mn>0</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>x</mi><mo>&gt;</mo><mn>0</mn></mrow></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">\sigma&#x27;(x)=\begin{cases} a &amp; x&lt;0 \\ 1 &amp; x&gt;0 \end{cases}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.051892em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.801892em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:3.0000299999999998em;vertical-align:-1.25003em"></span><span class="minner"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size4">{</span></span><span class="mord"><span class="mtable"><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.69em"><span style="top:-3.69em"><span class="pstrut" style="height:3.008em"></span><span class="mord"><span class="mord mathnormal">a</span></span></span><span style="top:-2.25em"><span class="pstrut" style="height:3.008em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.19em"><span></span></span></span></span></span><span class="arraycolsep" style="width:1em"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.69em"><span style="top:-3.69em"><span class="pstrut" style="height:3.008em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord">0</span></span></span><span style="top:-2.25em"><span class="pstrut" style="height:3.008em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.19em"><span></span></span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p>对于该激活函数输入小于 <code>0</code> 的部分，也可以得到一些值，而不是没有。</p><h3 id="池化层"><a class="anchor" href="#池化层">#</a> 池化层</h3><p>通常在连续的卷积层之间会周期性地插入一个池化层。其作用是逐渐降低数据体的空间尺寸，进一步地降低了参数量，降低计算资源耗费，也能有效控制过拟合。</p><p>池化层的超参数有过滤器的 <code>size</code> 以及步长 <code>stride</code><br><img data-src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6bf607d709ed4bb1ae31a13ca7bacce7~tplv-k3u1fbpfcp-watermark.image?" alt="image.png"></p><p>池化层没有参数，卷积层参数有神经网络需要学习的权重和偏差，而池化层只是给定了一个规则，即该层卷积核的参数已经被人为设定， <code>MAX POOLING</code> 还是 <code>MEAN POOLING</code> ，无需要学习，所以没有参数。</p><p>所以有没有重叠的可能？</p><p>对于池化层，一般会让每个区域没有重叠，因为我们只是想 <code>down sampling</code> ，只用得到一个值来表示这个区域，接着直接看下一个区域，以此类推即可。</p><p>Accepts a volume of size <code>W1*H1*D1</code></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>W</mi><mo>=</mo><mfrac><mrow><mi>W</mi><mo>−</mo><msub><mi>F</mi><mi>W</mi></msub></mrow><mi>S</mi></mfrac><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">W=\frac{W-F_W}{S}+1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.04633em;vertical-align:-.686em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.05764em">S</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.32833099999999993em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">W</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">1</span></span></span></span></span></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>H</mi><mo>=</mo><mfrac><mrow><mi>H</mi><mo>−</mo><msub><mi>F</mi><mi>H</mi></msub></mrow><mi>S</mi></mfrac><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">H=\frac{H-F_H}{S}+1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.08125em">H</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.04633em;vertical-align:-.686em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.05764em">S</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.08125em">H</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.32833099999999993em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.08125em">H</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">1</span></span></span></span></span></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>D</mi><mn>2</mn></msub><mo>=</mo><msub><mi>D</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">D_2=D_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span></span></p><p>Introduces zero parameters since it computes a fixed function of the input<br>Note : that it is not common to use zero-padding for pooling layers.</p><p><strong>MAX POOLING</strong></p><p>最大值子采样的核 <code>W</code> 中各权重值中只有一个为 <code>1</code> ，其余均为 <code>0</code> ，核 <code>W</code> 中为 <code>1</code> 的位置对应 <code>InputX</code> 被核 <code>W</code> 覆盖部分值最大的位置。最大值子采样的效果是把原图缩减至原来的 <code>1/4</code> ，并保留每个 <code>2*2</code> 区域的最强输入。</p><p><img data-src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a1e962508a1e4a35a7edd7eb6e0cc0a6~tplv-k3u1fbpfcp-watermark.image?" alt="image.png"></p><p><strong>MEAN POOLING</strong></p><p>均值子采样的核 <code>W</code> 中每个权重都是 <code>0.25</code> ，核 <code>W</code> 在原图 <code>InputX</code> 上的滑动的步长为 <code>2</code> 。均值子采样的效果相当于把原图模糊缩减至原来的 <code>1/4</code> 。</p><p><img data-src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4b33a0aeda3a4f1b8dd3403cd3e0173b~tplv-k3u1fbpfcp-watermark.image?" alt="image.png"></p><h3 id="全连接层"><a class="anchor" href="#全连接层">#</a> 全连接层</h3><p><img data-src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d6fae43f66514e43ac7b721e920bc986~tplv-k3u1fbpfcp-watermark.image?" alt="image.png"></p><p><img data-src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9f7261ca77aa4b9ea6c69bbfcf35cbf0~tplv-k3u1fbpfcp-watermark.image?" alt="image.png"></p><p>全连接层的作用主要是实现分类，该层对模型影响的参数有以下三个</p><ul><li>全连接层的总层数（长度）</li><li>单个全连接层的神经元数（宽度）</li><li>激活函数</li></ul><p><strong>如果全连接层宽度不变，增加长度</strong></p><p>神经元个数增加，模型复杂度提升；全连接层数加深，模型非线性表达能力提高。理论上都可以提高模型的学习能力。</p><p><strong>如果全连接层长度不变，增加宽度</strong></p><p>神经元个数增加，模型复杂度提升。理论上可以提高模型的学习能力。</p><p><strong>难度长度和宽度都是越多越好？</strong></p><p>肯定不是，学习能力太好容易造成过拟合，并且运算时间增加，效率变低。</p><p><strong>下图为 <code>LeNet</code> 来输出输入图像数字类别（ <code>0-9</code> ）的概率。</strong></p><p><img data-src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b73939d54b144b2abecda414e0f8c355~tplv-k3u1fbpfcp-watermark.image?" alt="image.png"></p><p>卷积层 <code>C5</code> 有 <code>120</code> 个卷积核，卷积核大小为 <code>5*5</code> ，因此生成 <code>120</code> 个特征图，没个特征图大小为 <code>1*1</code> ，每个 <code>feature map</code> 都与上一层（ <code>S4</code> ）所有特征图连接。所以该全连接层有 <code>120*（5*5*16+1）=48120</code> 个连接。</p><p>全连接层 <code>F6</code> ，共有 <code>84</code> 个神经元与 <code>C5</code> 层进行全连接，所以需要训练的参数是 <code>(120+1)*84=10164</code> ，如同传统神经网络， <code>F6</code> 层需要计算输入向量和权重向量之间的点积，再加上一个 <code>bias</code> ，然后将其传递给 <code>Sigmoid</code> 函数将数值规范化。</p><h2 id="常用的优化函数"><a class="anchor" href="#常用的优化函数">#</a> 常用的优化函数</h2><p>RMSprop、Adam、Adagrad、Momentum、批量梯度下降、随机梯度下降（ <code>SGD</code> ）、小批量梯度下降</p><p>参考<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8xMzcxOTEwOTc="># 深度学习中常用的优化算法（optimizer）</span></p><h2 id="典型的卷积神经网络"><a class="anchor" href="#典型的卷积神经网络">#</a> 典型的卷积神经网络</h2><p><img data-src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/03b5e4bf393c4fb69ff161059ef953c7~tplv-k3u1fbpfcp-watermark.image?" alt="image.png"></p><h3 id="alexnet"><a class="anchor" href="#alexnet">#</a> AlexNet</h3><p><img data-src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/574d8bfa2dc24f0982f75c952f78f773~tplv-k3u1fbpfcp-watermark.image?" alt="image.png"><br>Alexnet Block Diagram (source:oreilly.com)</p><ul><li>采用了非线性激活函数 <code>ReLU</code></li><li>采用数据增强</li><li>提出了 <code>DropOut</code> 防止过拟合</li><li>采用并行化 <code>GPU</code> 进行训练</li></ul><h3 id="vggnet"><a class="anchor" href="#vggnet">#</a> VGGNet</h3><p>smaller filters ，deeper networks</p><p><img data-src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/21507b44c9294b96bf033bf1692fdb3d~tplv-k3u1fbpfcp-watermark.image?" alt="image.png"></p><p><code>VGG</code> 相比 <code>AlexNet</code> 的一个改进是采用连续的几个 <code>3x3</code> 的卷积核代替 <code>AlexNet</code> 中的较大卷积核（ <code>11x11</code> ， <code>7x7</code> ， <code>5x5</code> ）。对于给定的感受野（与输出有关的输入图片的局部大小），采用堆积的小卷积核是优于采用大的卷积核，因为多层非线性层可以增加网络深度来保证学习更复杂的模式，而且代价还比较小（参数更少）。</p><p><img data-src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/03d7c8f22cab472aa548ba24ab4efb42~tplv-k3u1fbpfcp-watermark.image?" alt="VGG16 Block Diagram (source: neurohive.io)">VGG16 Block Diagram (source: <span class="exturl" data-url="aHR0cDovL25ldXJvaGl2ZS5pbw==">neurohive.io</span>)</p><p>WHY use smaller filters?( <code>3*3</code> conv)</p><p><img data-src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/98351d806f3e4d3789856fe511bb0e35~tplv-k3u1fbpfcp-watermark.image?" alt="image.png"></p><p>Stack of two <code>3*3</code> conv( <code>stride 1</code> ) layers has same <em>effective receptive field</em> as one <code>5*5</code> conv layer . Similarly , the effect of one <code>7*7</code> ( <code>11*11</code> ) conv layer can be achieved by implementing three (five) <code>3*3</code> conv layers with a stride of one .</p><p>这样做的主要目的是在保证具有相同感受野的条件下，提升了网络的深度，在一定程度上提升了神经网络的效果。</p><h3 id="resnet"><a class="anchor" href="#resnet">#</a> ResNet</h3><p><img data-src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/bf66dbfc316e45fb84ba963d77c0f2fa~tplv-k3u1fbpfcp-watermark.image?" alt="image.png"></p><p>针对深度学习的模型退化问题，当网络层数越深，理论上模型应当更优，但网络模型的效果在训练集和测试集上表现都不好。需要注意的是，这里的退化既不是梯度消失或者梯度爆炸，也不是过拟合；梯度消失说明根本没有进行学习，过拟合说明训练集上误差低，只是测试集上误差高。网络模型退化是由于冗余的网络层学习了不是恒等映射的参数造成的。</p><p><img data-src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/15c899fc504049f3a42868d807168ddc~tplv-k3u1fbpfcp-watermark.image?" alt="image.png"></p><p>F(x) is a residual mapping with respect to identity.</p><p>现有一个浅层网络，我们想通过向上堆积新层来建立深层网络，一个极端情况是增加的层没有学习，仅仅复制浅层网络的特征，这样新层就是恒等映射。</p><p>对于一个堆积层结构，当输入为 <code>x</code> 时，其学习到的特征记为 <code>H(x)</code> ，现在我们希望其可以学习到残差 <code>F(x)=H(x)-x</code> ，其原始的学习特征就是 <code>F(x)+x</code> 。</p><p>当残差为 <code>0</code> 时，此时堆积层仅仅做了上图右侧的 <code>short cut</code> （恒等映射），至少网络的性能不会下降；实际上残差不会为 <code>0</code> ，就会使得堆积层在输入特征的基础上学习到新的特征，从而拥有更好的性能。</p><p><code>ResNet</code> 解决了因网络加深而导致模型退化的问题，参数能够满足 <code>H(x)=x</code> 不就可以了，为什么要设计残差项 <code>F(x)=0</code> ？</p><p>对于网络退化，在引入 <code>ResNet</code> 之前，我们想让该层学习到的参数能够满足 <code>H(x)=x</code> ，即输入是 <code>x</code> ，经过该冗余层后，输出仍然为 <code>x</code> 。但实际上想要达到这种学习目的比较难。</p><p>而 <code>ResNet</code> 使用上图的结构，让 <code>H(x)=F(x)+x</code> ，要想让该冗余层能够恒等映射，只需要学习残差项 <code>F(x)=0</code> 。学习 <code>F(x)=0</code> 比学习 <code>H(x)=x</code> 要简单，原因有两点：一般每层网络中的参数初始化偏向于 <code>0</code> ，冗余层学习 <code>F(x)=0</code> 的更新参数能够更快收敛； <code>ReLU</code> 能在输入小于零时直接得到 <code>0</code> 的结果。</p><p>考虑到时间开销，<span class="exturl" data-url="aHR0cHM6Ly9vcGVuYWNjZXNzLnRoZWN2Zi5jb20vY29udGVudF9jdnByXzIwMTYvaHRtbC9IZV9EZWVwX1Jlc2lkdWFsX0xlYXJuaW5nX0NWUFJfMjAxNl9wYXBlci5odG1s">Deep Residual Learning for Image Recognition</span> 中提出了优化原来的残差学习结构为瓶颈结构。</p><p><img data-src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/539243eefd874384825170e3ff5c3f79~tplv-k3u1fbpfcp-watermark.image?" alt="image.png"></p><p>The three layers are <code>1*1</code> , <code>3*3</code> , and <code>1*1</code> convolutions, where the <code>1*1</code> layers are responsible for reducing and then increasing(restoring) dimensions, leaving the <code>3*3</code> layer a bottleneck with smaller input/output dimensions.</p><p>首尾的 <code>1*1</code> 卷积分别用来削减和恢复维度，相比于原结构，只留下了中间 <code>3*3</code> 瓶颈，这样网络的参数减少了很多，深度也加深了。</p><h2 id="编程题实验3"><a class="anchor" href="#编程题实验3">#</a> 编程题（实验 3）</h2><p><strong>考察重点</strong></p><p>网络的定义、如何获取定义好的网络（分类器）、定义损失函数（均方差、交叉熵）</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">def</span> <span class="token function">convolutional_neural_network</span><span class="token punctuation">(</span>img<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token comment"># 第一个卷积 - 池化层</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    conv1<span class="token operator">=</span>fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>img<span class="token punctuation">,</span> <span class="token comment"># 输入图像</span></pre></td></tr><tr><td data-num="4"></td><td><pre>        num_filters<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token comment"># 卷积核大小</span></pre></td></tr><tr><td data-num="5"></td><td><pre>        filter_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token comment"># 卷积核数量，它与输出的通道相同</span></pre></td></tr><tr><td data-num="6"></td><td><pre>        act<span class="token operator">=</span><span class="token string">"relu"</span><span class="token punctuation">)</span> <span class="token comment"># 激活函数</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    pool1 <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>pool2d<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="8"></td><td><pre>        <span class="token builtin">input</span><span class="token operator">=</span>conv1<span class="token punctuation">,</span> <span class="token comment"># 输入</span></pre></td></tr><tr><td data-num="9"></td><td><pre>        pool_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token comment"># 池化核大小</span></pre></td></tr><tr><td data-num="10"></td><td><pre>        pool_type<span class="token operator">=</span><span class="token string">'max'</span><span class="token punctuation">,</span> <span class="token comment"># 池化类型</span></pre></td></tr><tr><td data-num="11"></td><td><pre>        pool_stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token comment"># 池化步长</span></pre></td></tr><tr><td data-num="12"></td><td><pre>    conv_pool_1 <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>batch_norm<span class="token punctuation">(</span>pool1<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre>    </pre></td></tr><tr><td data-num="14"></td><td><pre>    <span class="token comment"># 第二个卷积 - 池化层</span></pre></td></tr><tr><td data-num="15"></td><td><pre>    conv2<span class="token operator">=</span>fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>conv_pool_1<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="16"></td><td><pre>        num_filters<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="17"></td><td><pre>        filter_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="18"></td><td><pre>        act<span class="token operator">=</span><span class="token string">"relu"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre>    pool2 <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>pool2d<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="20"></td><td><pre>        <span class="token builtin">input</span><span class="token operator">=</span>conv2<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="21"></td><td><pre>        pool_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="22"></td><td><pre>        pool_type<span class="token operator">=</span><span class="token string">'max'</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="23"></td><td><pre>        pool_stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="24"></td><td><pre>        global_pooling<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="25"></td><td><pre>    conv_pool_2 <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>batch_norm<span class="token punctuation">(</span>pool2<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="26"></td><td><pre>    </pre></td></tr><tr><td data-num="27"></td><td><pre>    <span class="token comment"># 第三个卷积 - 池化层</span></pre></td></tr><tr><td data-num="28"></td><td><pre>    conv3<span class="token operator">=</span>fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>conv_pool_2<span class="token punctuation">,</span> num_filters<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span> filter_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> act<span class="token operator">=</span><span class="token string">"relu"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="29"></td><td><pre>    pool3 <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>pool2d<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="30"></td><td><pre>        <span class="token builtin">input</span><span class="token operator">=</span>conv3<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="31"></td><td><pre>        pool_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="32"></td><td><pre>        pool_type<span class="token operator">=</span><span class="token string">'max'</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="33"></td><td><pre>        pool_stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="34"></td><td><pre>        global_pooling<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="35"></td><td><pre>    </pre></td></tr><tr><td data-num="36"></td><td><pre>    <span class="token comment"># 以 softmax 为激活函数的全连接输出层， 10 类数据输出 10 个数字</span></pre></td></tr><tr><td data-num="37"></td><td><pre>    prediction <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>fc<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>pool3<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="38"></td><td><pre>        size<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="39"></td><td><pre>        act<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="40"></td><td><pre>    <span class="token keyword">return</span> prediction</pre></td></tr></table></figure><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># 获取分类器，用 cnn 进行分类 </span></pre></td></tr><tr><td data-num="2"></td><td><pre>predict <span class="token operator">=</span> convolutional_neural_network<span class="token punctuation">(</span>images<span class="token punctuation">)</span></pre></td></tr></table></figure><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span> paddle </pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">import</span> paddle<span class="token punctuation">.</span>fluid <span class="token keyword">as</span> fluid</pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre>定义损失函数和准确率</pre></td></tr><tr><td data-num="5"></td><td><pre>cost1 <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>predict<span class="token punctuation">,</span> label<span class="token operator">=</span>label<span class="token punctuation">)</span> <span class="token comment"># 交叉熵</span></pre></td></tr><tr><td data-num="6"></td><td><pre>cost2 <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>mse_loss<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>predict<span class="token punctuation">,</span> label<span class="token operator">=</span>label<span class="token punctuation">)</span> <span class="token comment"># 均方差</span></pre></td></tr><tr><td data-num="7"></td><td><pre>avg_cost <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>cost1<span class="token punctuation">)</span> <span class="token comment"># 计算 cost 中所有元素的平均值 </span></pre></td></tr><tr><td data-num="8"></td><td><pre>acc <span class="token operator">=</span> fluid<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>accuracy<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>predict<span class="token punctuation">,</span> label<span class="token operator">=</span>label<span class="token punctuation">)</span> <span class="token comment"># 使用输入和标签计算准确率</span></pre></td></tr></table></figure><div class="tags"><a href="/tags/%E6%80%9D%E8%80%83/" rel="tag"><i class="ic i-tag"></i> 思考</a> <a href="/tags/Python/" rel="tag"><i class="ic i-tag"></i> Python</a> <a href="/tags/%E8%80%83%E5%89%8D%E5%A4%8D%E4%B9%A0/" rel="tag"><i class="ic i-tag"></i> 考前复习</a> <a href="/tags/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="tag"><i class="ic i-tag"></i> 卷积神经网络</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag"><i class="ic i-tag"></i> 深度学习</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">更新於</span> <time title="修改時間：2022-07-07 13:12:17" itemprop="dateModified" datetime="2022-07-07T13:12:17+08:00">2022-07-07</time> </span><span id="2022/04/20/卷积神经网络/" class="item leancloud_visitors" data-flag-title="卷积神经网络" title="閱讀次數"><span class="icon"><i class="ic i-eye"></i> </span><span class="text">閱讀次數</span> <span class="leancloud-visitors-count"></span> <span class="text">次</span></span></div><div class="reward"><button><i class="ic i-heartbeat"></i> 打賞</button><p>請我喝[茶]~(￣▽￣)~*</p><div id="qr"><div><img data-src="/images/wechatpay.png" alt="fygod 微信支付"><p>微信支付</p></div><div><img data-src="/images/alipay.png" alt="fygod 支付寶"><p>支付寶</p></div><div><img data-src="/images/paypal.png" alt="fygod PayPal"><p>PayPal</p></div></div></div><div id="copyright"><ul><li class="author"><strong>博主： </strong>fygod <i class="ic i-at"><em>@</em></i>2022</li><li class="link"><strong>文章連結：</strong> <a href="https://fygod1999.github.io/2022/04/20/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="卷积神经网络">https://fygod1999.github.io/2022/04/20/卷积神经网络/</a></li><li class="license"><strong>版權聲明： </strong>本網誌所有文章除特別聲明外，均採用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 許可協議。轉載請註明出處！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/2022/03/20/%E4%B8%80%E4%BA%9B%E6%9C%89%E8%B6%A3%E7%9A%84%E9%A2%98%E7%9B%AE/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;cdn.fygod.xyz&#x2F;uploads&#x2F;2022&#x2F;07&#x2F;09&#x2F;1&#x2F;1657379115&#x2F;qW3DjOwm_wallhaven-39leo3.jpg" title="一些有趣的题目"><span class="type">上一篇</span> <span class="category"><i class="ic i-flag"></i> 北冥有鱼</span><h3>一些有趣的题目</h3></a></div><div class="item right"><a href="/2022/05/12/%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;cdn.fygod.xyz&#x2F;uploads&#x2F;2022&#x2F;06&#x2F;03&#x2F;IADWoPGN_wallhaven-k7jmg6.jpg" title="希尔排序"><span class="type">下一篇</span> <span class="category"><i class="ic i-flag"></i> 北冥有鱼</span><h3>希尔排序</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目錄"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B1%80%E9%83%A8%E8%BF%9E%E6%8E%A5-%E6%9D%83%E5%80%BC%E5%85%B1%E4%BA%AB-%E5%A4%9A%E6%A0%B8%E5%8D%B7%E7%A7%AF"><span class="toc-number">1.</span> <span class="toc-text">局部连接、权值共享、多核卷积</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B1%80%E9%83%A8%E8%BF%9E%E6%8E%A5"><span class="toc-number">1.1.</span> <span class="toc-text">局部连接</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9D%83%E5%80%BC%E5%85%B1%E4%BA%AB"><span class="toc-number">1.2.</span> <span class="toc-text">权值共享</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E6%A0%B8%E5%8D%B7%E7%A7%AF"><span class="toc-number">1.3.</span> <span class="toc-text">多核卷积</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8D%95%E5%85%83"><span class="toc-number">2.</span> <span class="toc-text">卷积神经网络的基本单元</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E5%B1%82"><span class="toc-number">2.1.</span> <span class="toc-text">卷积层</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E5%B1%82"><span class="toc-number">2.2.</span> <span class="toc-text">激活函数层</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B1%A0%E5%8C%96%E5%B1%82"><span class="toc-number">2.3.</span> <span class="toc-text">池化层</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82"><span class="toc-number">2.4.</span> <span class="toc-text">全连接层</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B8%B8%E7%94%A8%E7%9A%84%E4%BC%98%E5%8C%96%E5%87%BD%E6%95%B0"><span class="toc-number">3.</span> <span class="toc-text">常用的优化函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B8%E5%9E%8B%E7%9A%84%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">4.</span> <span class="toc-text">典型的卷积神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#alexnet"><span class="toc-number">4.1.</span> <span class="toc-text">AlexNet</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#vggnet"><span class="toc-number">4.2.</span> <span class="toc-text">VGGNet</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#resnet"><span class="toc-number">4.3.</span> <span class="toc-text">ResNet</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BC%96%E7%A8%8B%E9%A2%98%E5%AE%9E%E9%AA%8C3"><span class="toc-number">5.</span> <span class="toc-text">编程题（实验 3）</span></a></li></ol></div><div class="related panel pjax" data-title="系列文章"><ul><li><a href="/2021/04/07/%E5%93%B2%E5%AD%A6%E5%AE%B6%E8%BF%9B%E9%A4%90/" rel="bookmark" title="哲学家进餐">哲学家进餐</a></li><li><a href="/2021/06/25/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/" rel="bookmark" title="进程间通信">进程间通信</a></li><li><a href="/2021/06/25/%E6%96%87%E4%BB%B6%E5%A4%8D%E5%88%B6/" rel="bookmark" title="文件复制">文件复制</a></li><li><a href="/2021/06/26/Trap/" rel="bookmark" title="Trap">Trap</a></li><li><a href="/2021/06/28/%E8%BF%9B%E7%A8%8B%E8%B0%83%E5%BA%A6/" rel="bookmark" title="进程调度">进程调度</a></li><li><a href="/2021/07/02/Ctrl-C/" rel="bookmark" title="Ctrl-C">Ctrl-C</a></li><li class="active"><a href="/2022/04/20/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="bookmark" title="卷积神经网络">卷积神经网络</a></li><li><a href="/2022/07/08/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E4%B8%8B%E4%B8%80%E4%B8%AA%E7%BB%93%E7%82%B9/" rel="bookmark" title="二叉树的下一个结点">二叉树的下一个结点</a></li><li><a href="/2022/07/10/%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E7%AC%ACK%E4%B8%AA%E6%9C%80%E5%A4%A7%E5%85%83%E7%B4%A0/" rel="bookmark" title="数组中的第K个最大元素">数组中的第K个最大元素</a></li><li><a href="/2022/07/11/%E5%8F%8D%E8%BD%AC%E9%93%BE%E8%A1%A8/" rel="bookmark" title="反转链表">反转链表</a></li><li><a href="/2022/07/12/%E4%BA%8C%E5%8F%89%E6%A0%91%E4%B8%AD%E7%9A%84%E6%9C%80%E5%A4%A7%E8%B7%AF%E5%BE%84%E5%92%8C/" rel="bookmark" title="二叉树中的最大路径和">二叉树中的最大路径和</a></li></ul></div><div class="overview panel" data-title="本站概覽"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="fygod" data-src="/images/avatar.jpg"><p class="name" itemprop="name">fygod</p><div class="description" itemprop="description">孤舟蓑笠翁，獨釣寒江雪</div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">59</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">4</span> <span class="name">分類</span></a></div><div class="item tags"><a href="/tags/"><span class="count">67</span> <span class="name">標籤</span></a></div></nav><div class="social"><span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL2Z5Z29kMTk5OQ==" title="https:&#x2F;&#x2F;github.com&#x2F;fygod1999"><i class="ic i-github"></i></span> <span class="exturl item twitter" data-url="aHR0cHM6Ly90d2l0dGVyLmNvbS9GWUdPRFlG" title="https:&#x2F;&#x2F;twitter.com&#x2F;FYGODYF"><i class="ic i-twitter"></i></span> <span class="exturl item zhihu" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3Blb3BsZS90dS14aW5nLXRpYW4teGlhLTE2" title="https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;tu-xing-tian-xia-16"><i class="ic i-zhihu"></i></span> <span class="exturl item music" data-url="aHR0cHM6Ly9tdXNpYy4xNjMuY29tLyMvdXNlci9ob21lP2lkPTE5NDM1NzQ4NDg=" title="https:&#x2F;&#x2F;music.163.com&#x2F;#&#x2F;user&#x2F;home?id&#x3D;1943574848"><i class="ic i-cloud-music"></i></span> <span class="exturl item weibo" data-url="aHR0cHM6Ly93ZWliby5jb20vNzIxMzIyNjQyOQ==" title="https:&#x2F;&#x2F;weibo.com&#x2F;7213226429"><i class="ic i-weibo"></i></span> <span class="exturl item email" data-url="bWFpbHRvOjIyMjY3NjI3OTVAcXEuY29t" title="mailto:2226762795@qq.com"><i class="ic i-envelope"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首頁</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>歸檔</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分類</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>標籤</a></li></ul></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-cloud"></i>傳送</a><ul class="submenu"><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>友鏈</a></li><li class="item"><a href="/links/" rel="section"><i class="ic i-magic"></i>網址</a></li></ul></li><li class="item"><a href="/comments/" rel="section"><i class="ic i-paper-plane"></i>留言</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/2022/03/20/%E4%B8%80%E4%BA%9B%E6%9C%89%E8%B6%A3%E7%9A%84%E9%A2%98%E7%9B%AE/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/2022/05/12/%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>隨機文章</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/%E7%A0%B4%E9%87%9C%E6%B2%89%E8%88%9F/" title="分類於 破釜沉舟">破釜沉舟</a></div><span><a href="/2022/06/24/2022.6.24/" title="2022.6.24">2022.6.24</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E7%A0%B4%E9%87%9C%E6%B2%89%E8%88%9F/" title="分類於 破釜沉舟">破釜沉舟</a></div><span><a href="/2022/06/23/2022.6.23/" title="2022.6.23">2022.6.23</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E5%8C%97%E5%86%A5%E6%9C%89%E9%B1%BC/" title="分類於 北冥有鱼">北冥有鱼</a></div><span><a href="/2022/05/14/%E5%A0%86%E6%8E%92%E5%BA%8F/" title="堆排序">堆排序</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E7%A0%B4%E9%87%9C%E6%B2%89%E8%88%9F/" title="分類於 破釜沉舟">破釜沉舟</a></div><span><a href="/2022/06/15/2022.6.15/" title="2022.6.15">2022.6.15</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E7%A0%B4%E9%87%9C%E6%B2%89%E8%88%9F/" title="分類於 破釜沉舟">破釜沉舟</a></div><span><a href="/2022/06/30/2022.6.30/" title="2022.6.30">2022.6.30</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E7%A0%B4%E9%87%9C%E6%B2%89%E8%88%9F/" title="分類於 破釜沉舟">破釜沉舟</a></div><span><a href="/2022/06/12/2022.6.12/" title="2022.6.12">2022.6.12</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E7%9B%B2%E4%BA%BA%E6%91%B8%E8%B1%A1/" title="分類於 盲人摸象">盲人摸象</a></div><span><a href="/2021/06/28/%E8%BF%9B%E7%A8%8B%E8%B0%83%E5%BA%A6/" title="进程调度">进程调度</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E7%9B%B2%E4%BA%BA%E6%91%B8%E8%B1%A1/" title="分類於 盲人摸象">盲人摸象</a></div><span><a href="/2021/06/25/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/" title="进程间通信">进程间通信</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E7%A0%B4%E9%87%9C%E6%B2%89%E8%88%9F/" title="分類於 破釜沉舟">破釜沉舟</a></div><span><a href="/2022/07/01/2022.7.1/" title="2022.7.1">2022.7.1</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E7%A0%B4%E9%87%9C%E6%B2%89%E8%88%9F/" title="分類於 破釜沉舟">破釜沉舟</a></div><span><a href="/2022/06/08/2022.6.8/" title="2022.6.8">2022.6.8</a></span></li></ul></div><div><h2>最新評論</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2021 – <span itemprop="copyrightYear">2022</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">fygod @ Scarecrow</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="站點總字數">237k 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="站點閱讀時長">3:35</span></div><div class="powered-by">基於 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"2022/04/20/卷积神经网络/",favicon:{show:"（●´3｀●）復活成功",hide:"(´Д｀) 瀏覽器崩潰啦"},search:{placeholder:"文章搜索",empty:"關於 「 ${query} 」 ，什麼也沒搜到",stats:"${time} ms 內找到 ${hits} 條結果"},valine:!0,copy_tex:!0,katex:!0,fancybox:!0,copyright:'複製成功，轉載請遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 協議。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html><!-- rebuild by hrmmi -->